{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9415fe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from random import seed,sample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from random import seed,sample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c061ef1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lime_tabular\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m## Below a LimeTabularExplainer object based on the training dataset. \u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m## We'll be using this explainer object to explain a random sample from the test dataset.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m explainer \u001b[38;5;241m=\u001b[39m (lime\n\u001b[0;32m      6\u001b[0m              \u001b[38;5;241m.\u001b[39mlime_tabular\n\u001b[1;32m----> 7\u001b[0m              \u001b[38;5;241m.\u001b[39mLimeTabularExplainer(training_data \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[38;5;241m.\u001b[39mto_numpy(), \n\u001b[0;32m      8\u001b[0m                                    training_labels \u001b[38;5;241m=\u001b[39m y_train,                                   \n\u001b[0;32m      9\u001b[0m                                    feature_names \u001b[38;5;241m=\u001b[39m X_feats, \n\u001b[0;32m     10\u001b[0m                                    class_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo Fraud\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFraud\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     11\u001b[0m                                    kernel_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     12\u001b[0m                                    verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m ))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "import lime\n",
    "from lime import lime_tabular\n",
    "## Below a LimeTabularExplainer object based on the training dataset. \n",
    "## We'll be using this explainer object to explain a random sample from the test dataset.\n",
    "explainer = (lime\n",
    "             .lime_tabular\n",
    "             .LimeTabularExplainer(training_data = X_train.to_numpy(), \n",
    "                                   training_labels = y_train,                                   \n",
    "                                   feature_names = X_feats, \n",
    "                                   class_names = ['No Fraud','Fraud'],\n",
    "                                   kernel_width=3,\n",
    "                                   verbose = True ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104beac6",
   "metadata": {},
   "source": [
    "## FRAUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59906c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Actual :     \", y_test.iloc[13])\n",
    "print(\"Predicted:   \", clf.predict(X_test.iloc[13].to_numpy().reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e097ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance( X_test.iloc[13].to_numpy(), \n",
    "                                  clf.predict_proba )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8784545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4388a21b",
   "metadata": {},
   "source": [
    "## NO FRAUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8291b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Actual :     \", y_test.iloc[0])\n",
    "print(\"Predicted:   \", clf.predict(X_test.iloc[0].to_numpy().reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5836e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance( X_test.iloc[0].to_numpy(), \n",
    "                                  clf.predict_proba )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5ed766",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6644cc7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d509264e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0210f373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b83bf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f93ab6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Information():\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        This class give some brief information about the datasets.\n",
    "        Information introduced in R language style\n",
    "        \"\"\"\n",
    "        print(\"Information object created\")\n",
    "\n",
    "    def _get_missing_values(self,data):\n",
    "        \"\"\"\n",
    "        Find missing values of given datad\n",
    "        :param data: checked its missing value\n",
    "        :return: Pandas Series object\n",
    "        \"\"\"\n",
    "        #Getting sum of missing values for each feature\n",
    "        missing_values = data.isnull().sum()\n",
    "        #Feature missing values are sorted from few to many\n",
    "        missing_values.sort_values(ascending=False, inplace=True)\n",
    "        \n",
    "        #Returning missing values\n",
    "        return missing_values\n",
    "\n",
    "    def info(self,data):\n",
    "        \"\"\"\n",
    "        print feature name, data type, number of missing values and ten samples of \n",
    "        each feature\n",
    "        :param data: dataset information will be gathered from\n",
    "        :return: no return value\n",
    "        \"\"\"\n",
    "        feature_dtypes=data.dtypes\n",
    "        self.missing_values=self._get_missing_values(data)\n",
    "\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        print(\"{:16} {:16} {:25} {:16}\".format(\"Feature Name\".upper(),\n",
    "                                            \"Data Format\".upper(),\n",
    "                                            \"# of Missing Values\".upper(),\n",
    "                                            \"Samples\".upper()))\n",
    "        for feature_name, dtype, missing_value in zip(self.missing_values.index.values,\n",
    "                                                      feature_dtypes[self.missing_values.index.values],\n",
    "                                                      self.missing_values.values):\n",
    "            print(\"{:18} {:19} {:19} \".format(feature_name, str(dtype), str(missing_value)), end=\"\")\n",
    "            for v in data[feature_name].values[:5]:\n",
    "                print(v, end=\",\")\n",
    "            print()\n",
    "\n",
    "        print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00954b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess():\n",
    "\n",
    "    def __init__(self):\n",
    "        print(\"Preprocess object created\")\n",
    "    \n",
    "    ### add fillna method?\n",
    "\n",
    "    def drop(self, data, cols, axs):\n",
    "        data=data.drop(cols, axis=axs)\n",
    "        return data\n",
    "\n",
    "    def _feature_engineering(self,data,drop_cols):\n",
    "        df_new = data.loc[(data.type == 'TRANSFER') | (data.type == 'CASH_OUT')]\n",
    "        #adding new feat -> errorbalanceOrg and errorbalanceDest because after transactions the data doesnt correlate\n",
    "        df_new[\"errorbalanceOrg\"] = df_new.newbalanceOrig + df_new.amount - df_new.oldbalanceOrg\n",
    "        df_new[\"errorbalanceDest\"] = df_new.oldbalanceDest + df_new.amount - df_new.newbalanceDest\n",
    "        # add new Hour feat\n",
    "        df_new[\"HourOfDay\"] = np.nan # initializing feature column\n",
    "        df_new.HourOfDay = df_new.step % 24\n",
    "        \n",
    "        data = self.drop(df_new, drop_cols,1)\n",
    "        return data\n",
    "\n",
    "    def _label_encoder(self,data):\n",
    "        labelEncoder=LabelEncoder()\n",
    "        for column in data.columns.values:\n",
    "            if 'int64'==data[column].dtype or 'float64'==data[column].dtype or 'int64'==data[column].dtype:\n",
    "                continue\n",
    "            labelEncoder.fit(data[column])\n",
    "            data[column]=labelEncoder.transform(data[column])\n",
    "        return data\n",
    "    \n",
    "    def _scale_and_splitXY(self, data):\n",
    "        X = data.drop(\"isFraud\",1)\n",
    "        Y = data.isFraud\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = pd.DataFrame(scaler.fit_transform(X),columns = X.columns)\n",
    "        return X_scaled, Y\n",
    "    \n",
    "    def _train_test_sets(self, X, Y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)\n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a4719f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0861b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.clf = DecisionTreeClassifier(random_state=0)\n",
    "    \n",
    "    def split(self, test_size):\n",
    "        Xd = self.X\n",
    "        yd = self.y\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(Xd, yd, test_size = test_size, random_state = 42)\n",
    "    \n",
    "    def fit(self):\n",
    "        self.model = self.clf.fit(self.X_train, self.y_train)\n",
    "    \n",
    "    def predict(self):\n",
    "        result = self.clf.predict(self.X_test)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d2dbd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8703c7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess object created\n"
     ]
    }
   ],
   "source": [
    "pp = Preprocess()\n",
    "feat_data = pp._feature_engineering(fraud_df, ['nameOrig', 'nameDest', 'isFlaggedFraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07351d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = pp._label_encoder(feat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b097dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled, Y = pp._scale_and_splitXY(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5f3a6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(X_scaled, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bd656f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.split(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "902f6e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "163dd1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55aef07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9999602946856242\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \",     model.model.score(model.X_test, model.y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ff080d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
